{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poj_G = nx.read_edgelist('./nx_create/nx_graph_df_poj.csv'\n",
    "                     , create_using=nx.DiGraph()\n",
    "                     , nodetype=int\n",
    "                     , data=[('weight', int)]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(poj_G.edges(data=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(poj_G.edges(data=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(poj_G) \n",
    "plt.figure(figsize = (15, 15)) \n",
    "node_item_id = 1001\n",
    "#networkx.draw_networkx_labels(purchasedAsinEgoGraph, pos, font_size = 18) \n",
    "edgewidth = [d['weight'] for (u, v, d) in poj_G.edges(data = True)]\n",
    "nx.draw(poj_G, pos = pos, node_size = 50, node_color='g', edge_color= edgewidth, style = 'solid')\n",
    "nx.draw_networkx_nodes(poj_G, pos = pos, nodelist= [node_item_id], node_color= 'r', node_size = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std = 5\n",
    "threshold = 3\n",
    "GivenNodeIslands = nx.Graph()\n",
    "for f, t, e in poj_G.edges(data = True):\n",
    "    if e['weight'] >= threshold:\n",
    "        GivenNodeIslands.add_edge(f, t, weight = e['weight'])\n",
    "node_TrimGraph = nx.Graph(GivenNodeIslands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10)) \n",
    "neg1 = 1000\n",
    "# (1000, 1001, {'weight': 453})\n",
    "neg2 = 2056\n",
    "#(1000, 2056, {'weight': 14})\n",
    "#networkx.draw_networkx_labels(purchasedAsinEgoTrimGraph, pos, font_size = 18) \n",
    "edgewidth = [d['weight'] for (u, v, d) in node_TrimGraph.edges(data = True)]\n",
    "nx.draw_networkx_nodes(node_TrimGraph, pos = pos, nodelist= nx.nodes(node_TrimGraph), node_color='g') \n",
    "nx.draw_networkx_edges(node_TrimGraph, pos = pos, edgelist= node_TrimGraph.edges)\n",
    "nx.draw_networkx_nodes(node_TrimGraph, pos = pos, nodelist= [node_item_id], node_color= 'r') #ego node\n",
    "nx.draw_networkx_nodes(node_TrimGraph, pos = pos, nodelist= [neg1], node_color= 'b') #ego node\n",
    "nx.draw_networkx_nodes(node_TrimGraph, pos = pos, nodelist= [neg2], node_color= 'r') #ego node\n",
    "plt.show()\n",
    "#共现次数越大越近\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo[1001],demo[1000],demo[2056]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_TrimGraph.edges(data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.number_of_nodes(node_TrimGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# pr = nx.pagerank(poj_G)\n",
    "# pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_item_id_Neighbors = [n for n in node_TrimGraph.neighbors(node_item_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_item_id_Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poj = pd.read_csv('./nx_create/nx_graph_df_poj.csv',header=None,sep=' ',names=['source','target','weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "node_dict_degree_clus = {}\n",
    "pr = nx.pagerank(poj_G)\n",
    "\n",
    "degree_centralityG = nx.degree_centrality(poj_G)\n",
    "\n",
    "eigenvector_centralityG = nx.eigenvector_centrality(poj_G,weight='weight')\n",
    "\n",
    "average_degree_connectivityG = nx.average_degree_connectivity(poj_G, weight=\"weight\")\n",
    "\n",
    "harmonic_centralityG = nx.harmonic_centrality(poj_G,distance='weight')\n",
    "\n",
    "betweenness_centralityG = nx.betweenness_centrality(poj_G,weight='weight')\n",
    "for node_id in tqdm(nx.nodes(poj_G)):\n",
    "    metadata = {}\n",
    "    metadata['PageRank'] = round(pr[node_id],5)\n",
    "    metadata['DegreeCentrality'] = round(degree_centralityG[node_id],5)\n",
    "    metadata['EigenvectorCentrality'] = round(eigenvector_centralityG[node_id],5)\n",
    "    metadata['HarmonicCentrality'] = round(harmonic_centralityG[node_id],5)\n",
    "    metadata['BetweennessCentrality'] = round(betweenness_centralityG[node_id],5)#介数中心性 betweenness\n",
    "    ego = nx.ego_graph(poj_G, node_id, distance='weight')\n",
    "    node_dict_degree_clus[node_id] = metadata\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_dict_degree_clus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(node_dict_degree_clus, open( 'poj_node_dict_Centrality_clus.pkl', 'wb'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo = pd.DataFrame(node_dict_degree_clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_dict_degree_clus.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "poj_sna = []\n",
    "for item_id,metadata in tqdm(node_dict_degree_clus.items()):\n",
    "    singledata = {}\n",
    "    singledata['item_id'] = item_id\n",
    "    singledata['PageRank'] = metadata['PageRank']\n",
    "    singledata['DegreeCentrality'] = metadata['DegreeCentrality']\n",
    "    singledata['EigenvectorCentrality'] = metadata['EigenvectorCentrality']\n",
    "    singledata['HarmonicCentrality'] = metadata['HarmonicCentrality']\n",
    "    singledata['BetweennessCentrality'] = metadata['BetweennessCentrality']\n",
    "\n",
    "    poj_sna.append(singledata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poj_sna_analysis = pd.DataFrame(poj_sna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poj_sna_analysis_item_id = poj_sna_analysis.set_index('item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poj_sna_analysis_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sanple_item_id_Neighbors = [n for n in node_TrimGraph.neighbors(node_item_id)]\n",
    "sanple_item_id_Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poj_sna_analysis_item_id.loc[sanple_item_id_Neighbors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "poj_sna_analysis_item_id.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "\n",
    "poj_sna_analysis['HarmonicCentrality'] = poj_sna_analysis[['HarmonicCentrality']].apply(max_min_scaler)\n",
    "poj_sna_analysis_item_id['HarmonicCentrality'] = poj_sna_analysis_item_id[['HarmonicCentrality']].apply(max_min_scaler)\n",
    "\n",
    "\n",
    "##\n",
    "poj_sna_analysis['PageRank'] = poj_sna_analysis[['PageRank']].apply(max_min_scaler)\n",
    "poj_sna_analysis_item_id['PageRank'] = poj_sna_analysis_item_id[['PageRank']].apply(max_min_scaler)\n",
    "\n",
    "##\n",
    "poj_sna_analysis['DegreeCentrality'] = poj_sna_analysis[['DegreeCentrality']].apply(max_min_scaler)\n",
    "poj_sna_analysis_item_id['DegreeCentrality'] = poj_sna_analysis_item_id[['DegreeCentrality']].apply(max_min_scaler)\n",
    "##\n",
    "\n",
    "poj_sna_analysis['EigenvectorCentrality'] = poj_sna_analysis[['EigenvectorCentrality']].apply(max_min_scaler)\n",
    "poj_sna_analysis_item_id['EigenvectorCentrality'] = poj_sna_analysis_item_id[['EigenvectorCentrality']].apply(max_min_scaler)\n",
    "#\n",
    "\n",
    "#BetweennessCentrality\n",
    "poj_sna_analysis['BetweennessCentrality'] = poj_sna_analysis[['BetweennessCentrality']].apply(max_min_scaler)\n",
    "poj_sna_analysis_item_id['BetweennessCentrality'] = poj_sna_analysis_item_id[['BetweennessCentrality']].apply(max_min_scaler)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poj_sna_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.fit(poj_sna_analysis[['PageRank','DegreeCentrality','EigenvectorCentrality','HarmonicCentrality','BetweennessCentrality']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = neigh.kneighbors(poj_sna_analysis_item_id.loc[1409,:].values.reshape((1,-1)),10, return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poj_sna_analysis.loc[ind.tolist()[0]].iloc[:,0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall_item_num = 11\n",
    "poj = pd.read_csv('./nx_create/nx_graph_df_poj.csv',header=None,sep=' ',names=['source','target','weight'])\n",
    "\n",
    "source_target = list(zip(poj.source.tolist(),poj.target.tolist()))\n",
    "source_target_dict = {}\n",
    "\n",
    "item_recall_list = {}\n",
    "for iid in tqdm(poj_sna_analysis['item_id'].unique()):\n",
    "    ind = neigh.kneighbors(poj_sna_analysis_item_id.loc[iid,:].values.reshape((1,-1)),recall_item_num, return_distance=False)\n",
    "    item_recall_list[iid] = poj_sna_analysis.loc[ind.tolist()[0]].iloc[:,0].tolist()[1:]\n",
    "#     print(item_recall_list)\n",
    "\n",
    "eva_data = []\n",
    "for iid,group in poj.groupby('source'):\n",
    "    if len(group)>10:\n",
    "        tmp = list(zip(group.source,group.target))[:10]\n",
    "    else: tmp = list(zip(group.source,group.target))\n",
    "    eva_data.extend(tmp[:])   \n",
    "\n",
    "\n",
    "def metrics_recall(eva_data,item_recall_list, k=10):\n",
    "    item_num = len(item_recall_list)\n",
    "    \n",
    "    hit_num = 0\n",
    "    score=0\n",
    "    past = []\n",
    "    for iid, recall_list in tqdm(item_recall_list.items()):#从item列表中读取每一个item\n",
    "        # 获取前k个召回的结果\n",
    "        tmp_recall_items = item_recall_list[iid][:k] #返回一个item的列表\n",
    "        for s,t in eva_data:\n",
    "            if s == iid and t in list(tmp_recall_items):#在评估数据中查找是否存在推荐列表中\n",
    "                rank = list(tmp_recall_items).index(t)\n",
    "                score += 1.0/(rank+1.0)\n",
    "                hit_num += 1\n",
    "                break\n",
    "    \n",
    "\n",
    "    ###\n",
    "    \n",
    "\n",
    "    ###\n",
    "            \n",
    "    mrr_score = round(score* 1.0 / item_num, 5)\n",
    "    hit_rate = round(hit_num * 1.0 / item_num, 5)\n",
    "    print(' topk: ', k, ' : ', 'hit_num: ', hit_num, 'hit_rate: ', hit_rate, 'user_num : ', item_num)\n",
    "    print(' topk: ', k, ' : ', 'hit_num: ', hit_num, 'mrr_score: ', mrr_score, 'user_num : ', item_num)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_recall(source_target,item_recall_list,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_recall(source_target,item_recall_list,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_recall(source_target,item_recall_list,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh1 = NearestNeighbors(n_neighbors=1)\n",
    "neigh1.fit(poj_sna_analysis[['DegreeCentrality','EigenvectorCentrality','HarmonicCentrality','BetweennessCentrality']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_item_num = 11\n",
    "poj = pd.read_csv('./nx_create/nx_graph_df_poj.csv',header=None,sep=' ',names=['source','target','weight'])\n",
    "\n",
    "source_target = list(zip(poj.source.tolist(),poj.target.tolist()))\n",
    "source_target_dict = {}\n",
    "\n",
    "item_recall_list = {}\n",
    "for iid in tqdm(poj_sna_analysis['item_id'].unique()):\n",
    "    ind = neigh1.kneighbors(poj_sna_analysis_item_id.loc[iid,['DegreeCentrality','EigenvectorCentrality','HarmonicCentrality','BetweennessCentrality']].values.reshape((1,-1)),recall_item_num, return_distance=False)\n",
    "    item_recall_list[iid] = poj_sna_analysis.loc[ind.tolist()[0]].iloc[:,0].tolist()[1:]\n",
    "#     print(item_recall_list)\n",
    "\n",
    "eva_data = []\n",
    "for iid,group in poj.groupby('source'):\n",
    "    if len(group)>10:\n",
    "        tmp = list(zip(group.source,group.target))[:10]\n",
    "    else: tmp = list(zip(group.source,group.target))\n",
    "    eva_data.extend(tmp[:])   \n",
    "\n",
    "\n",
    "def metrics_recall(eva_data,item_recall_list, k=10):\n",
    "    item_num = len(item_recall_list)\n",
    "    \n",
    "    hit_num = 0\n",
    "    score=0\n",
    "    past = []\n",
    "    for iid, recall_list in tqdm(item_recall_list.items()):#从item列表中读取每一个item\n",
    "        # 获取前k个召回的结果\n",
    "        tmp_recall_items = item_recall_list[iid][:k] #返回一个item的列表\n",
    "        for s,t in eva_data:\n",
    "            if s == iid and t in list(tmp_recall_items):#在评估数据中查找是否存在推荐列表中\n",
    "                rank = list(tmp_recall_items).index(t)\n",
    "                score += 1.0/(rank+1.0)\n",
    "                hit_num += 1\n",
    "                break\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    ###\n",
    "            \n",
    "    mrr_score = round(score* 1.0 / item_num, 5)\n",
    "    hit_rate = round(hit_num * 1.0 / item_num, 5)\n",
    "    print(' topk: ', k, ' : ', 'hit_num: ', hit_num, 'hit_rate: ', hit_rate, 'user_num : ', item_num)\n",
    "    print(' topk: ', k, ' : ', 'hit_num: ', hit_num, 'mrr_score: ', mrr_score, 'user_num : ', item_num)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_recall(source_target,item_recall_list,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_recall(source_target,item_recall_list,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_recall(source_target,item_recall_list,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poj_sna_analysis_item_id.loc[iid,['DegreeCentrality','EigenvectorCentrality','HarmonicCentrality','BetweennessCentrality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(36,36))\n",
    "nx.draw(poj_G,with_labels=True, font_weight='bold',width = 0.5)\n",
    "\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### poj[poj.weight>5].source.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poj[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eva_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
